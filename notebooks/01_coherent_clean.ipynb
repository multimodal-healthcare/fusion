{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion\n",
    "\n",
    "> Fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemonpie.basics import *\n",
    "from lemonpie.preprocessing import clean\n",
    "from fastai.imports import *\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 21:07:55,589\tINFO services.py:1245 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.86.91',\n",
       " 'raylet_ip_address': '192.168.86.91',\n",
       " 'redis_address': '192.168.86.91:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2022-09-28_21-07-53_738287_11841/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-09-28_21-07-53_738287_11841/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2022-09-28_21-07-53_738287_11841',\n",
       " 'metrics_export_port': 55296,\n",
       " 'node_id': 'f829f0cd921d340e36f6e16565515d477a36173ef7b06d427d37de6b'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERENT_DATA_STORE = '/home/vinod/code/datasets/coherent'\n",
    "COHERENT_DATAGEN_DATE = '08-10-2021'\n",
    "COHERENT_CONDITIONS = {\n",
    "    \"heart_failure\" : \"88805009\",\n",
    "    \"coronary_heart\" : \"53741008\",\n",
    "    \"myocardial_infarction\" : \"22298006\",\n",
    "    \"stroke\" : \"230690007\",\n",
    "    \"cardiac_arrest\" : \"410429000\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherent Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retain only patients with FHIR bundles.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retain_fhir_patients(coherent_path, csv_names):\n",
    "    \"\"\"Retain only patients with FHIR bundles.\"\"\"\n",
    "\n",
    "    # read pids with FHIR bundles\n",
    "    file_list = os.listdir(f'{coherent_path}/output/fhir')\n",
    "    fhir_pids = [((file).split(\"_\")[-1]).split(\".\")[0] for file in file_list]\n",
    "\n",
    "    # filter and retain only FHIR patients in all files\n",
    "    print(f\"Writing filtered files to {coherent_path}/raw_original/\")\n",
    "    for file in csv_names:\n",
    "        old_df = pd.read_csv(f\"{coherent_path}/output/csv/{file}.csv\", low_memory=False)\n",
    "        if file == 'patients':\n",
    "            fhir_mask = old_df.Id.isin(fhir_pids)\n",
    "        else:\n",
    "            fhir_mask = old_df.PATIENT.isin(fhir_pids)\n",
    "        new_df = old_df[fhir_mask]\n",
    "        assert len(new_df) == fhir_mask.sum(), f\"Count error in {file}\"\n",
    "        new_df.to_csv(f\"{coherent_path}/raw_original/{file}.csv\", index=False)\n",
    "        print(f\"Created {file} with {len(new_df)} records.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove ECG from observations and create ecg.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveout_ecg(coherent_path):\n",
    "    \"\"\"Move ECG data out of Observations into its own csv.\"\"\"\n",
    "    \n",
    "    old_obs = pd.read_csv(f\"{coherent_path}/raw_original/observations.csv\", low_memory=False)\n",
    "    ecg_obs = old_obs[old_obs[\"CODE\"] == \"29303009\"]\n",
    "    new_obs = old_obs.drop(ecg_obs.index)\n",
    "    assert len(new_obs) == len(old_obs) - len(ecg_obs), \"Mismatch after ECG removal from Observations\"\n",
    "    new_obs.to_csv(f\"{coherent_path}/raw_original/observations.csv\", index=False)\n",
    "    print(f\"Updated observations without ECG data = {len(new_obs)} records\")\n",
    "\n",
    "    ecg_obs.reset_index(inplace=True, drop=True)\n",
    "    odd_indxs = [i for i in range(1, len(ecg_obs), 2)]\n",
    "    ecg_obs.drop(odd_indxs, inplace=True)\n",
    "    ecg_obs.drop(columns=[\"ENCOUNTER\", \"CODE\", \"DESCRIPTION\", \"UNITS\", \"TYPE\"], inplace=True)\n",
    "    ecg_obs.rename(str.lower, axis='columns', inplace=True)\n",
    "    ecg_obs.to_csv(f\"{coherent_path}/ecg.csv\", index=False)\n",
    "    print(f\"Saved ECG data to {coherent_path}/ecg.csv with {len(ecg_obs)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create `modalities.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modalities_csv(coherent_path):\n",
    "    \"\"\"Create modalities csv.\"\"\"\n",
    "    \n",
    "    # dna - counts off by 1, because no FHIR bunde for 1 pt with dna data\n",
    "    dna_files = os.listdir(f'{coherent_path}/output/dna')\n",
    "    dna_pids = [file.split(\"_\")[-2] for file in dna_files]\n",
    "    \n",
    "    # mri\n",
    "    mri_files = os.listdir(f'{coherent_path}/output/dicom')\n",
    "    mri_pids = [file.split(\"_\")[-1].split(\".\")[0][:-1]  for file in mri_files]\n",
    "    \n",
    "    # ecg\n",
    "    ecg_data = pd.read_csv(f\"{coherent_path}/ecg.csv\")\n",
    "    ecg_pids = ecg_data.patient.unique()\n",
    "\n",
    "    # create modalities csv\n",
    "    patients = pd.read_csv(f\"{coherent_path}/raw_original/patients.csv\", low_memory=False)\n",
    "    modalities = patients[[\"Id\", \"FIRST\", \"LAST\"]].copy()\n",
    "    modalities.rename(str.lower, axis='columns', inplace=True)\n",
    "\n",
    "    modalities[\"mri\"] = modalities.id.isin(mri_pids)\n",
    "    modalities[\"dna\"] = modalities.id.isin(dna_pids)\n",
    "    modalities[\"ecg\"] = modalities.id.isin(ecg_pids)\n",
    "\n",
    "    modalities[\"mri\"].replace({True:1, False:0}, inplace=True)\n",
    "    modalities[\"dna\"].replace({True:10, False:0}, inplace=True)\n",
    "    modalities[\"ecg\"].replace({True:20, False:0}, inplace=True)\n",
    "    modalities[\"type\"] = modalities[\"mri\"] + modalities[\"dna\"] + modalities[\"ecg\"]\n",
    "\n",
    "    modalities.to_csv(f\"{coherent_path}/modalities.csv\", index=False)\n",
    "    print(f\"Saved modalities to {coherent_path}/modalities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherent_preprocess(coherent_path=COHERENT_DATA_STORE, csv_names=FILENAMES):\n",
    "    \"\"\"Perform coherent-specific preprocessing.\"\"\"\n",
    "\n",
    "    # create raw_original dir\n",
    "    raw_dir = Path(f'{coherent_path}/raw_original')\n",
    "    raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # filter patients to keep only those with FHIR bundles\n",
    "    print(\"--Filtering & retaining patients with FHIR bundles--\")\n",
    "    retain_fhir_patients(coherent_path, csv_names)\n",
    "\n",
    "    # move ECG data out of observations\n",
    "    print(\"--Moving ECG data out of observations into its own ecg.csv--\")\n",
    "    moveout_ecg(coherent_path)\n",
    "\n",
    "    # create modalities file\n",
    "    print(\"--Creating modalities.csv--\")\n",
    "    create_modalities_csv(coherent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Filtering & retaining patients with FHIR bundles--\n",
      "Writing filtered files to /home/vinod/code/datasets/coherent/raw_original/\n",
      "Created patients with 1278 records.\n",
      "Created observations with 705436 records.\n",
      "Created allergies with 106 records.\n",
      "Created careplans with 6135 records.\n",
      "Created medications with 209401 records.\n",
      "Created imaging_studies with 3752 records.\n",
      "Created procedures with 56092 records.\n",
      "Created conditions with 15956 records.\n",
      "Created immunizations with 11900 records.\n",
      "--Moving ECG data out of observations into its own ecg.csv--\n",
      "Updated observations without ECG data = 703292 records\n",
      "Saved ECG data to /home/vinod/code/datasets/coherent/ecg.csv with 1072 records\n",
      "--Creating modalities.csv--\n",
      "Saved modalities to /home/vinod/code/datasets/coherent/modalities.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pandas/core/frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "coherent_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = pd.read_csv(f\"{COHERENT_DATA_STORE}/modalities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>mri</th>\n",
       "      <th>dna</th>\n",
       "      <th>ecg</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9c452d24-00b0-d58f-4cd5-b82bd6695646</td>\n",
       "      <td>Sydney660</td>\n",
       "      <td>Champlin946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40c7c5d7-e21d-0aec-3023-bf613f37a5f1</td>\n",
       "      <td>Ryan260</td>\n",
       "      <td>Turcotte120</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e4c173c1-99ab-865e-4094-970fd1ac8df8</td>\n",
       "      <td>Johanna547</td>\n",
       "      <td>Vandervort697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6f4d77e9-2203-03a3-8966-92a22a21000a</td>\n",
       "      <td>Shawnta32</td>\n",
       "      <td>Zboncak558</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a58de3fd-f026-902b-55c1-872dc042e0c5</td>\n",
       "      <td>Contessa946</td>\n",
       "      <td>Leuschke194</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>22e4f915-e209-4ff0-b9c9-112b5146b8c3</td>\n",
       "      <td>Sammie902</td>\n",
       "      <td>Crist667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>bc0cb6be-1caa-e53f-f4c4-e25d91363698</td>\n",
       "      <td>Herb645</td>\n",
       "      <td>Crooks415</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>11d3a003-57bf-d281-60b0-8ba6a523c557</td>\n",
       "      <td>Bernardo699</td>\n",
       "      <td>Quesada500</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>d70cac07-9852-8260-1daa-6dc227f70b39</td>\n",
       "      <td>Gilberto712</td>\n",
       "      <td>Jasso472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>3107760e-1dce-a177-4122-725241aae61a</td>\n",
       "      <td>Andreas188</td>\n",
       "      <td>Hauck852</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id        first           last  mri  \\\n",
       "0     9c452d24-00b0-d58f-4cd5-b82bd6695646    Sydney660    Champlin946    0   \n",
       "1     40c7c5d7-e21d-0aec-3023-bf613f37a5f1      Ryan260    Turcotte120    0   \n",
       "2     e4c173c1-99ab-865e-4094-970fd1ac8df8   Johanna547  Vandervort697    0   \n",
       "3     6f4d77e9-2203-03a3-8966-92a22a21000a    Shawnta32     Zboncak558    0   \n",
       "4     a58de3fd-f026-902b-55c1-872dc042e0c5  Contessa946    Leuschke194    1   \n",
       "...                                    ...          ...            ...  ...   \n",
       "1273  22e4f915-e209-4ff0-b9c9-112b5146b8c3    Sammie902       Crist667    0   \n",
       "1274  bc0cb6be-1caa-e53f-f4c4-e25d91363698      Herb645      Crooks415    0   \n",
       "1275  11d3a003-57bf-d281-60b0-8ba6a523c557  Bernardo699     Quesada500    0   \n",
       "1276  d70cac07-9852-8260-1daa-6dc227f70b39  Gilberto712       Jasso472    0   \n",
       "1277  3107760e-1dce-a177-4122-725241aae61a   Andreas188       Hauck852    0   \n",
       "\n",
       "      dna  ecg  type  \n",
       "0       0   20    20  \n",
       "1      10    0    10  \n",
       "2       0   20    20  \n",
       "3      10    0    10  \n",
       "4      10    0    11  \n",
       "...   ...  ...   ...  \n",
       "1273    0   20    20  \n",
       "1274   10    0    10  \n",
       "1275   10    0    10  \n",
       "1276    0   20    20  \n",
       "1277   10    0    10  \n",
       "\n",
       "[1278 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 10, 11,  1, 30, 31, 21,  0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modalities.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>mri</th>\n",
       "      <th>dna</th>\n",
       "      <th>ecg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>615</td>\n",
       "      <td>615</td>\n",
       "      <td>615</td>\n",
       "      <td>615</td>\n",
       "      <td>615</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  first  last  mri  dna  ecg\n",
       "type                                 \n",
       "0       2      2     2    2    2    2\n",
       "1     110    110   110  110  110  110\n",
       "10    615    615   615  615  615  615\n",
       "11    145    145   145  145  145  145\n",
       "20    261    261   261  261  261  261\n",
       "21     17     17    17   17   17   17\n",
       "30    102    102   102  102  102  102\n",
       "31     26     26    26   26   26   26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modalities.groupby([\"type\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits:: train: 0.8, valid: 0.1, test: 0.1\n",
      "Split patients into:: Train: 1022, Valid: 128, Test: 128 -- Total before split: 1278\n",
      "Saved train data to /home/vinod/code/datasets/coherent/raw_split/train\n",
      "Saved valid data to /home/vinod/code/datasets/coherent/raw_split/valid\n",
      "Saved test data to /home/vinod/code/datasets/coherent/raw_split/test\n",
      "Completed - valid\n",
      "Completed - test\n",
      "\u001b[2m\u001b[36m(pid=30058)\u001b[0m Saved cleaned \"test\" data to /home/vinod/code/datasets/coherent/cleaned/test\n",
      "\u001b[2m\u001b[36m(pid=30062)\u001b[0m Saved cleaned \"valid\" data to /home/vinod/code/datasets/coherent/cleaned/valid\n",
      "\u001b[2m\u001b[36m(pid=30065)\u001b[0m Saved cleaned \"train\" data to /home/vinod/code/datasets/coherent/cleaned/train\n",
      "\u001b[2m\u001b[36m(pid=30065)\u001b[0m Saved vocab code tables to /home/vinod/code/datasets/coherent/cleaned/train/codes\n",
      "Completed - train\n"
     ]
    }
   ],
   "source": [
    "clean.clean_raw_ehrdata(COHERENT_DATA_STORE, 0.1, 0.1, COHERENT_CONDITIONS, COHERENT_DATAGEN_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs, valid_dfs, test_dfs = clean.load_cleaned_ehrdata(COHERENT_DATA_STORE)\n",
    "code_dfs = clean.load_ehr_vocabcodes(COHERENT_DATA_STORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in train_dfs:\n",
    "#     display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "thispt = train_dfs[0].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient                      967d5226-f8c4-60a8-b882-6ef803af88a6\n",
       "birthdate                                              1930-04-29\n",
       "heart_failure                                               False\n",
       "heart_failure_age                                             NaN\n",
       "coronary_heart                                              False\n",
       "coronary_heart_age                                            NaN\n",
       "myocardial_infarction                                       False\n",
       "myocardial_infarction_age                                     NaN\n",
       "stroke                                                       True\n",
       "stroke_age                                                   87.0\n",
       "cardiac_arrest                                              False\n",
       "cardiac_arrest_age                                            NaN\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thispt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in code_dfs:\n",
    "#     display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure condition counts match - after extracting `y` for each patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`patients` dfs after cleaning, with `y` extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_train, pts_valid, pts_test = train_dfs[0], valid_dfs[0], test_dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conditions` dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd_train, cnd_valid, cnd_test = train_dfs[8], valid_dfs[8], test_dfs[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests to ensure counts match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train dfs...\n",
      "Tests passed for train - all condition counts match\n",
      "Checking valid dfs...\n",
      "Tests passed for valid - all condition counts match\n",
      "Checking test dfs...\n",
      "Tests passed for test - all condition counts match\n"
     ]
    }
   ],
   "source": [
    "clean.test_extract_ys([pts_train, pts_valid, pts_test],[cnd_train, cnd_valid, cnd_test], conditions_dict=COHERENT_CONDITIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'heart_failure': 257,\n",
       "  'coronary_heart': 260,\n",
       "  'myocardial_infarction': 110,\n",
       "  'stroke': 573,\n",
       "  'cardiac_arrest': 137},\n",
       " {'heart_failure': 43,\n",
       "  'coronary_heart': 38,\n",
       "  'myocardial_infarction': 15,\n",
       "  'stroke': 61,\n",
       "  'cardiac_arrest': 20},\n",
       " {'heart_failure': 32,\n",
       "  'coronary_heart': 38,\n",
       "  'myocardial_infarction': 20,\n",
       "  'stroke': 64,\n",
       "  'cardiac_arrest': 23}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.get_label_counts([pts_train, pts_valid, pts_test], conditions_dict=COHERENT_CONDITIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptids_by_modality = modalities.groupby([\"type\"])[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = {}\n",
    "for modality, ptids in ptids_by_modality:\n",
    "\n",
    "    train_ids = pts_train[pts_train[\"patient\"].isin(ptids)][\"patient\"]\n",
    "    valid_ids = pts_valid[pts_valid[\"patient\"].isin(ptids)][\"patient\"]\n",
    "    test_ids = pts_test[pts_test[\"patient\"].isin(ptids)][\"patient\"]\n",
    "\n",
    "    filtered[modality] = [train_ids, valid_ids, test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "10\n",
      "11\n",
      "20\n",
      "21\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for modality in filtered.keys():\n",
    "    print(modality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality, ptids = next(iter(ptids_by_modality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indx\n",
       "299    72d3121f-639c-4824-876f-7c19dd197b7c\n",
       "567    47b3acc7-8688-6559-534f-daaec268e3c3\n",
       "Name: patient, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_train[pts_train[\"patient\"].isin(ptids)][\"patient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: patient, dtype: object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts_valid[pts_valid[\"patient\"].isin(ptids)][\"patient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small run through lemonpie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps as detailed here - https://corazonlabs.github.io/lemonpie/quick_walkthru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cf702de-f751-45dc-93c8-61dc5e6ad297",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['heart_failure', 'coronary_heart', 'myocardial_infarction', 'stroke', 'cardiac_arrest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20 years of patient data from Jan 01 1995**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemonpie import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "518ae1be-20ce-4e57-99b3-44dada24b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherent_data = data.EHRData(\n",
    "    COHERENT_DATA_STORE, \n",
    "    labels,     \n",
    "    age_start='1995-01-01',\n",
    "    age_range=20,\n",
    "    start_is_date=True,\n",
    "    age_in_months=False, \n",
    "    lazy_load_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemonpie.preprocessing import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "demograph_dims, rec_dims, demograph_dims_wd, rec_dims_wd = vocab.get_all_emb_dims(vocab.EhrVocabList.load(COHERENT_DATA_STORE))\n",
    "train_dl, valid_dl, train_pos_wts, valid_pos_wts = coherent_data.get_data(bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl), len(valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647b954a",
   "metadata": {},
   "source": [
    "#### `EHR_LSTM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lemonpie import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe59926c-f0e1-4b29-9fe8-b4cd484fc4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.EHR_LSTM(\n",
    "    demograph_dims,\n",
    "    rec_dims,\n",
    "    demograph_dims_wd,\n",
    "    rec_dims_wd,\n",
    "    len(labels),\n",
    "    train_pos_wts, \n",
    "    valid_pos_wts,\n",
    "    optim=\"adam\",\n",
    "    base_lr=0.001,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0557fd29-491f-438d-b72e-778ba513901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EHR_LSTM(\n",
       "  (train_loss_fn): BCEWithLogitsLoss()\n",
       "  (valid_loss_fn): BCEWithLogitsLoss()\n",
       "  (embs): ModuleList(\n",
       "    (0): Embedding(40, 8)\n",
       "    (1): Embedding(16, 8)\n",
       "    (2): Embedding(128, 8)\n",
       "    (3): Embedding(8, 8)\n",
       "    (4): Embedding(8, 8)\n",
       "    (5): Embedding(8, 8)\n",
       "    (6): Embedding(8, 8)\n",
       "    (7): Embedding(264, 16)\n",
       "    (8): Embedding(192, 16)\n",
       "    (9): Embedding(8, 8)\n",
       "    (10): Embedding(184, 16)\n",
       "  )\n",
       "  (embgs): ModuleList(\n",
       "    (0): EmbeddingBag(664, 16, mode=mean)\n",
       "    (1): EmbeddingBag(16, 8, mode=mean)\n",
       "    (2): EmbeddingBag(56, 8, mode=mean)\n",
       "    (3): EmbeddingBag(240, 16, mode=mean)\n",
       "    (4): EmbeddingBag(16, 8, mode=mean)\n",
       "    (5): EmbeddingBag(144, 8, mode=mean)\n",
       "    (6): EmbeddingBag(192, 16, mode=mean)\n",
       "    (7): EmbeddingBag(16, 8, mode=mean)\n",
       "  )\n",
       "  (input_dp): InputDropout()\n",
       "  (lstm): LSTM(88, 88, num_layers=4, batch_first=True, dropout=0.3)\n",
       "  (lin): Sequential(\n",
       "    (0): Linear(in_features=208, out_features=416, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=416, out_features=832, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=832, out_features=1664, bias=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Dropout(p=0.3, inplace=False)\n",
       "    (9): Linear(in_features=1664, out_features=3328, bias=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (lin_o): Linear(in_features=3328, out_features=5, bias=True)\n",
       "  (train_metrics): MetricCollection(\n",
       "    (AUROC): AUROC(),\n",
       "    prefix=train/\n",
       "  )\n",
       "  (valid_metrics): MetricCollection(\n",
       "    (AUROC): AUROC(),\n",
       "    prefix=valid/\n",
       "  )\n",
       "  (test_metrics): MetricCollection(\n",
       "    (AUROC): AUROC(),\n",
       "    prefix=test/\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(precision=16, accelerator='gpu', devices=-1, max_epochs=5) #, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name          | Type              | Params\n",
      "-----------------------------------------------------\n",
      "0  | train_loss_fn | BCEWithLogitsLoss | 0     \n",
      "1  | valid_loss_fn | BCEWithLogitsLoss | 0     \n",
      "2  | embs          | ModuleList        | 12.0 K\n",
      "3  | embgs         | ModuleList        | 19.5 K\n",
      "4  | input_dp      | InputDropout      | 0     \n",
      "5  | lstm          | LSTM              | 250 K \n",
      "6  | lin           | Sequential        | 7.4 M \n",
      "7  | lin_o         | Linear            | 16.6 K\n",
      "8  | train_metrics | MetricCollection  | 0     \n",
      "9  | valid_metrics | MetricCollection  | 0     \n",
      "10 | test_metrics  | MetricCollection  | 0     \n",
      "-----------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "15.320    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  8.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/14 [00:00<?, ?it/s]                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1891: PossibleUserWarning: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [00:02<00:00,  5.56it/s, loss=0.871, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 14/14 [00:02<00:00,  5.21it/s, loss=0.871, v_num=5]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, tensor([2., 2., 6., 1., 5.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl, test_pos_wts = coherent_data.get_test_data()\n",
    "len(test_dl), test_pos_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:219: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 10.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/AUROC         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6931756734848022     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/AUROC        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6931756734848022    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/AUROC': 0.6931756734848022}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherent_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 331)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = pd.read_csv(f\"{COHERENT_DATA_STORE}/output/csv/imaging_studies.csv\")\n",
    "cnd = pd.read_csv(f\"{COHERENT_DATA_STORE}/output/csv/conditions.csv\")\n",
    "mri_encs = img[img.MODALITY_CODE == \"MR\"].ENCOUNTER\n",
    "#smh = Silent micro-hemorrhage\n",
    "smh = cnd[cnd.ENCOUNTER.isin(mri_encs)].CODE == 723857007\n",
    "assert smh.sum() == len(mri_encs)\n",
    "smh.sum(), len(mri_encs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('lemonpie')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5f90d37e0c39959df55936ee810057807de324814919599137c4c82f94e911f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
