{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from lemonpie.basics import *\n",
    "from lemonpie.preprocessing import vocab\n",
    "from lemonpie.preprocessing.transform import *\n",
    "from lemonpie.data import *\n",
    "from lemonpie import models\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, AUROC, Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERENT_DATA_STORE = '/home/vinod/code/datasets/coherent'\n",
    "COHERENT_DATAGEN_DATE = '08-10-2021'\n",
    "COHERENT_CONDITIONS = {\n",
    "    \"heart_failure\" : \"88805009\",\n",
    "    \"coronary_heart\" : \"53741008\",\n",
    "    \"myocardial_infarction\" : \"22298006\",\n",
    "    \"stroke\" : \"230690007\",\n",
    "    \"cardiac_arrest\" : \"410429000\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heart_failure',\n",
       " 'coronary_heart',\n",
       " 'myocardial_infarction',\n",
       " 'stroke',\n",
       " 'cardiac_arrest']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COHERENT_LABELS = list(COHERENT_CONDITIONS.keys())\n",
    "COHERENT_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518ae1be-20ce-4e57-99b3-44dada24b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherent_data = MultimodalEHRData(\n",
    "    COHERENT_DATA_STORE, \n",
    "    COHERENT_LABELS,     \n",
    "    age_start=240,\n",
    "    age_range=120,\n",
    "    start_is_date=False,\n",
    "    age_in_months=True, \n",
    "    lazy_load_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demograph_dims, rec_dims, demograph_dims_wd, rec_dims_wd = vocab.get_all_emb_dims(vocab.EhrVocabList.load(COHERENT_DATA_STORE))\n",
    "dls, pos_wts = coherent_data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['0', '21', '30', '31', '11', '1', '20', '10'],\n",
       " 'valid': ['21', '30', '31', '11', '1', '20', '10'],\n",
       " 'test': ['21', '30', '31', '11', '1', '20', '10']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherent_data.modality_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f874511d250>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7f8744f2e8e0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f8745106580>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dls[\"train\"]\n",
    "valid_dl = dls[\"valid\"]\n",
    "test_dl = dls[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimodal Models - One Per Modality\n",
    "These are stubs / dummys to be replaced by the real ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnimodalModel(pl.LightningModule):\n",
    "    def __init__(self, input_dims: tuple):\n",
    "        super().__init__()\n",
    "\n",
    "        # args\n",
    "        self.input_dims = input_dims\n",
    "\n",
    "        # model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 5),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x[0].size() == self.input_dims, f\"Expected {self.input_dims}, got {x[0].size()}\"\n",
    "        bs = len(x)\n",
    "        fake_x = torch.randn((bs, 10), device=self.device)\n",
    "        return self.model(fake_x)\n",
    "\n",
    "    def training_step(self, *args, **kwargs):\n",
    "        return super().training_step(*args, **kwargs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return super().configure_optimizers()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5356, 0.5292, 0.4622, 0.5050, 0.5145],\n",
       "        [0.5703, 0.5492, 0.4860, 0.4505, 0.4999],\n",
       "        [0.5437, 0.5564, 0.4891, 0.4984, 0.5146]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_model = UnimodalModel((4,4))\n",
    "mri_model(torch.randn(3,4,4)) # batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "mri_trainer = pl.Trainer(max_epochs=3, accelerator='gpu', devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.0 K \n",
      "-------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:03<00:00,  5.27it/s, loss=nan, v_num=13]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:03<00:00,  5.26it/s, loss=nan, v_num=13]\n"
     ]
    }
   ],
   "source": [
    "mri_trainer.fit(mri_model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_trainer.save_checkpoint(\"./mri_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4793, 0.4843, 0.5255, 0.5074, 0.5071],\n",
       "        [0.4920, 0.4513, 0.5616, 0.5017, 0.4978]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_model = UnimodalModel((3,2))\n",
    "dna_model(torch.randn(2,3,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "dna_trainer = pl.Trainer(max_epochs=3, accelerator='gpu', devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.0 K \n",
      "-------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:03<00:00,  5.40it/s, loss=nan, v_num=14]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:03<00:00,  5.39it/s, loss=nan, v_num=14]\n"
     ]
    }
   ],
   "source": [
    "dna_trainer.fit(dna_model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_trainer.save_checkpoint(\"./dna_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5351, 0.5408, 0.5217, 0.4983, 0.4411],\n",
       "        [0.5453, 0.5590, 0.5234, 0.5139, 0.4308],\n",
       "        [0.5662, 0.5273, 0.4979, 0.4695, 0.4290],\n",
       "        [0.5508, 0.5548, 0.5337, 0.4901, 0.4438]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_model = UnimodalModel((5,))\n",
    "ecg_model(torch.randn((4,5,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "ecg_trainer = pl.Trainer(max_epochs=3, accelerator='gpu', devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.0 K \n",
      "-------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:04<00:00,  5.24it/s, loss=nan, v_num=15]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:04<00:00,  5.23it/s, loss=nan, v_num=15]\n"
     ]
    }
   ],
   "source": [
    "ecg_trainer.fit(ecg_model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_trainer.save_checkpoint(\"./ecg_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_model = models.EHR_LSTM(\n",
    "    demograph_dims,\n",
    "    rec_dims,\n",
    "    demograph_dims_wd,\n",
    "    rec_dims_wd,\n",
    "    len(COHERENT_LABELS),\n",
    "    pos_wts[\"train\"], \n",
    "    pos_wts[\"valid\"],\n",
    "    optim=\"adam\",\n",
    "    base_lr=0.001,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "ehr_trainer = pl.Trainer(precision=16, accelerator='gpu', devices=-1, max_epochs=3)\n",
    "# ehr_output = ehr_trainer.test(ehr_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | train_loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | valid_loss_fn | BCEWithLogitsLoss | 0     \n",
      "2 | embs          | ModuleList        | 12.0 K\n",
      "3 | embgs         | ModuleList        | 19.5 K\n",
      "4 | input_dp      | InputDropout      | 0     \n",
      "5 | lstm          | LSTM              | 250 K \n",
      "6 | linear        | Sequential        | 7.4 M \n",
      "7 | train_metrics | MetricCollection  | 0     \n",
      "8 | valid_metrics | MetricCollection  | 0     \n",
      "9 | test_metrics  | MetricCollection  | 0     \n",
      "----------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "15.320    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 28/28 [00:09<00:00,  2.92it/s, loss=1.03, v_num=16]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 28/28 [00:09<00:00,  2.82it/s, loss=1.03, v_num=16]\n"
     ]
    }
   ],
   "source": [
    "ehr_trainer.fit(ehr_model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Lightning warning details](https://github.com/Lightning-AI/lightning/issues/10349#issuecomment-961340903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_trainer.save_checkpoint(\"./ehr_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimodal Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class MRIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datastore: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        self.mri_dir = f\"{datastore}/output/dicom\"\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        mri_fname = glob.glob(f\"{self.mri_dir}/*{i}*\")\n",
    "        if len(mri_fname) == 1:\n",
    "            return torch.full(self.tensor_sz, 1)\n",
    "        else:\n",
    "            raise Exception(f\"MRI filename match error - found {len(mri_fname)} files with ptid: {i}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class DNADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datastore: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        self.dna_dir = f\"{datastore}/output/dna\"\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        dna_fname = glob.glob(f\"{self.dna_dir}/*{i}*\")\n",
    "        if len(dna_fname) == 1:\n",
    "            return torch.full(self.tensor_sz, 10)\n",
    "        else:\n",
    "            raise Exception(f\"DNA filename match error - found {len(dna_fname)} files with ptid: {i}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class ECGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datastore: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        ecg_data = pd.read_csv(f\"{datastore}/ecg.csv\")\n",
    "        self.ecg_pids = ecg_data.patient.unique()\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        if i in self.ecg_pids:\n",
    "            return torch.full(self.tensor_sz, 20)\n",
    "        else:\n",
    "            raise Exception(f\"ptid: {i} - not found in ECG data.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modality Type | Modalities            |   \n",
    "|---\t        |---\t                |\n",
    "| **0**\t        | **EHR**               |\n",
    "| **1**         | EHR + **MRI**         |\n",
    "| **10**        | EHR + **DNA**         |      \n",
    "| 11   \t        | EHR + MRI + DNA       |\n",
    "| **20**        | EHR + **ECG**         |\n",
    "| 21            | EHR + MRI + ECG       |\n",
    "| 30            | EHR + DNA + ECG       |\n",
    "| 31            | EHR + MRI + DNA + ECG |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ptid:1a82483d-7eb2-d5e0-1e1f-398ba129b18b, birthdate:1936-12-22, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       "  ptid:6dc8bd6b-e2a8-92bf-613d-8b477eb87d7c, birthdate:1911-12-23, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       "  ptid:844a37ff-ce26-6338-fd6a-0bc1e925a702, birthdate:1933-03-15, [('heart_failure', True), ('coronary_heart', False)].., device:cpu],\n",
       " tensor([[1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.]]),\n",
       " [21, 21, 21],\n",
       " [tensor([[[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]],\n",
       "  \n",
       "          [[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]],\n",
       "  \n",
       "          [[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]]]),\n",
       "  tensor([[20, 20, 20, 20, 20],\n",
       "          [20, 20, 20, 20, 20],\n",
       "          [20, 20, 20, 20, 20]])]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(valid_dl))   \n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts, ys, mod_type, other = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5317, 0.5461, 0.4880, 0.4909, 0.4987],\n",
       "        [0.5642, 0.5709, 0.4845, 0.5405, 0.4524],\n",
       "        [0.5330, 0.4908, 0.3036, 0.4859, 0.5562]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(ehr_model(pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_input, ecg_input = other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mri_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-31758db4068a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmri_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mri_model' is not defined"
     ]
    }
   ],
   "source": [
    "mri_model(mri_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4668, 0.4984, 0.5840, 0.4353, 0.3662],\n",
       "        [0.5483, 0.4521, 0.5888, 0.5441, 0.3307],\n",
       "        [0.5181, 0.3867, 0.4538, 0.5974, 0.3182]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_model(ecg_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_late_fusion(dl, verbose=False):\n",
    "\n",
    "    all_batches = []\n",
    "    total_length = 0\n",
    "\n",
    "    for batch in dl:\n",
    "\n",
    "        batch_output = []\n",
    "        pts, ys, mod_type, other = batch\n",
    "        \n",
    "        total_length += len(pts)\n",
    "        if verbose:\n",
    "            print(f\"modality: {mod_type[0]}, length: {len(pts)}, first ptid: {pts[0].ptid}\")\n",
    "\n",
    "        batch_output.append(torch.sigmoid(ehr_model(pts)))\n",
    "\n",
    "        if mod_type[0] == 1:\n",
    "            mri_input = other \n",
    "            batch_output.append(mri_model(mri_input))\n",
    "\n",
    "        elif mod_type[0] == 10:\n",
    "            dna_input = other \n",
    "            batch_output.append(dna_model(dna_input))\n",
    "            \n",
    "        elif mod_type[0] == 11:\n",
    "            mri_input, dna_input = other \n",
    "            batch_output.append(mri_model(mri_input))\n",
    "            batch_output.append(dna_model(dna_input))\n",
    "\n",
    "        elif mod_type[0] == 20:\n",
    "            ecg_input = other \n",
    "            batch_output.append(ecg_model(ecg_input))\n",
    "\n",
    "        elif mod_type[0] == 21:\n",
    "            mri_input, ecg_input = other \n",
    "            batch_output.append(mri_model(mri_input))\n",
    "            batch_output.append(ecg_model(ecg_input))\n",
    "\n",
    "        elif mod_type[0] == 30:\n",
    "            dna_input, ecg_input = other \n",
    "            batch_output.append(dna_model(dna_input))\n",
    "            batch_output.append(ecg_model(ecg_input))\n",
    "\n",
    "        elif mod_type[0] == 31:\n",
    "            mri_input, dna_input, ecg_input = other\n",
    "            batch_output.append(mri_model(mri_input))\n",
    "            batch_output.append(dna_model(dna_input))\n",
    "            batch_output.append(ecg_model(ecg_input))\n",
    "\n",
    "        # avg across multimodal models for every patient in batch\n",
    "        avgd = torch.mean(torch.stack(batch_output), dim=0)         \n",
    "        all_batches.append(avgd)\n",
    "\n",
    "\n",
    "    print(f\"Completed {total_length} patients.\")\n",
    "\n",
    "    # flatten across batches - list of lists (batches) to flat\n",
    "    output = [pt for batch in all_batches for pt in batch]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mri_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-070d5b4c663e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_late_fusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-21aeca779ecf>\u001b[0m in \u001b[0;36mrun_late_fusion\u001b[0;34m(dl, verbose)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmod_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mmri_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mbatch_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmri_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mbatch_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mri_model' is not defined"
     ]
    }
   ],
   "source": [
    "test_result = run_late_fusion(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modality: 21, length: 3, first ptid: 1a82483d-7eb2-d5e0-1e1f-398ba129b18b\n",
      "modality: 30, length: 13, first ptid: 2e1cf98c-70ce-4f8f-36da-b2eef4960ecc\n",
      "modality: 31, length: 2, first ptid: 4a1a224f-54d6-66f1-3755-4c8489f2a5de\n",
      "modality: 11, length: 14, first ptid: aead835e-66f2-d3b9-099c-c33844a70748\n",
      "modality: 1, length: 12, first ptid: 972f6a59-3921-36bc-64bb-253d6241748b\n",
      "modality: 20, length: 34, first ptid: e1875ec6-e10f-c9d8-d388-fd3abfbc4a87\n",
      "modality: 10, length: 50, first ptid: 1e73e6da-68f0-0ffc-4062-a4647b5b67c4\n",
      "Completed 128 patients.\n"
     ]
    }
   ],
   "source": [
    "valid_result = run_late_fusion(valid_dl, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1022 patients.\n"
     ]
    }
   ],
   "source": [
    "train_result = run_late_fusion(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_result) == len(valid_result) == 128\n",
    "assert len(train_result) == 1022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts, y, m, other = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ptid:1a82483d-7eb2-d5e0-1e1f-398ba129b18b, birthdate:1936-12-22, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       " ptid:6dc8bd6b-e2a8-92bf-613d-8b477eb87d7c, birthdate:1911-12-23, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       " ptid:844a37ff-ce26-6338-fd6a-0bc1e925a702, birthdate:1933-03-15, [('heart_failure', True), ('coronary_heart', False)].., device:cpu]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_model = UnimodalModel.load_from_checkpoint(\"./mri_model_pth\", input_dims=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_layers_trunc = list(mri_model.model.children())[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_model.model = nn.Sequential(*mri_layers_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_repr = mri_model(mri_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 30])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_repr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ehr_model = models.EHR_LSTM.load_from_checkpoint(\n",
    "    \"./ehr_model_pth\",\n",
    "    demograph_dims=demograph_dims,\n",
    "    rec_dims=rec_dims,\n",
    "    demograph_dims_wd=demograph_dims_wd,\n",
    "    rec_dims_wd=rec_dims_wd,\n",
    "    labels=len(COHERENT_LABELS),\n",
    "    train_pos_wts=pos_wts[\"train\"], \n",
    "    valid_pos_wts=pos_wts[\"valid\"],\n",
    "    optim=\"adam\",\n",
    "    base_lr=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_layers_trunc = list(ehr_model.linear.children())[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_model.linear = nn.Sequential(*ehr_layers_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ehr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_repr = ehr_model(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3328])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ehr_repr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated = torch.concat((ehr_repr, mri_repr), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3358])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointFusion(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "            demograph_dims,\n",
    "            rec_dims,\n",
    "            demograph_wd,\n",
    "            rec_wd,\n",
    "            num_labels,\n",
    "            train_pos_wts,\n",
    "            valid_pos_wts\n",
    "            ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        ## args\n",
    "        self.train_loss_fn = nn.BCEWithLogitsLoss(pos_weight=train_pos_wts)\n",
    "        self.valid_loss_fn = nn.BCEWithLogitsLoss(pos_weight=valid_pos_wts)\n",
    "\n",
    "\n",
    "        # ehr\n",
    "        self.ehr_model = models.EHR_LSTM.load_from_checkpoint(\n",
    "            \"./ehr_model.pth\",\n",
    "            demograph_dims=demograph_dims,\n",
    "            rec_dims=rec_dims,\n",
    "            demograph_dims_wd=demograph_dims_wd,\n",
    "            rec_dims_wd=rec_dims_wd,\n",
    "            labels=len(COHERENT_LABELS),\n",
    "            train_pos_wts=pos_wts[\"train\"], \n",
    "            valid_pos_wts=pos_wts[\"valid\"],\n",
    "            optim=\"adam\",\n",
    "            base_lr=0.001,\n",
    "        )\n",
    "        ehr_layers_trunc = list(self.ehr_model.linear.children())[:-2]\n",
    "        self.ehr_model.linear = nn.Sequential(*ehr_layers_trunc)\n",
    "\n",
    "        # mri\n",
    "        self.mri_model = UnimodalModel.load_from_checkpoint(\"./mri_model.pth\", input_dims=(4,4))\n",
    "        mri_layers_trunc = list(self.mri_model.model.children())[:-2]\n",
    "        self.mri_model.model = nn.Sequential(*mri_layers_trunc)\n",
    "        \n",
    "        # dna\n",
    "        self.dna_model = UnimodalModel.load_from_checkpoint(\"./dna_model.pth\", input_dims=(3,2))\n",
    "        dna_layers_trunc = list(self.dna_model.model.children())[:-2]\n",
    "        self.dna_model.model = nn.Sequential(*dna_layers_trunc)\n",
    "\n",
    "        # ecg\n",
    "        self.ecg_model = UnimodalModel.load_from_checkpoint(\"./ecg_model.pth\", input_dims=(5,))\n",
    "        ecg_layers_trunc = list(self.ecg_model.model.children())[:-2]\n",
    "        self.ecg_model.model = nn.Sequential(*ecg_layers_trunc)\n",
    "\n",
    "        # model\n",
    "        self.repr_dims = {}\n",
    "        self.repr_dims[\"ehr\"] = self.ehr_model.repr_dim\n",
    "        self.repr_dims[\"mri\"] = 30\n",
    "        self.repr_dims[\"dna\"] = 30\n",
    "        self.repr_dims[\"ecg\"] = 30\n",
    "        self.repr_dims[\"total\"] = sum(self.repr_dims.values())\n",
    "\n",
    "        self.model = nn.Sequential(nn.Linear(self.repr_dims[\"total\"], 4000),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(4000, 5000),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(5000, 5),\n",
    "                      nn.Sigmoid())\n",
    "        \n",
    "        ## metrics\n",
    "        metrics = MetricCollection(\n",
    "            [\n",
    "                # Accuracy(),\n",
    "                AUROC(num_classes=num_labels, pos_label=1, average=\"micro\"),\n",
    "                # Recall(),\n",
    "                # Precision(),\n",
    "                # AveragePrecision(num_classes)\n",
    "            ]\n",
    "        )\n",
    "        self.train_metrics = metrics.clone(prefix=\"train/\")\n",
    "        self.valid_metrics = metrics.clone(prefix=\"valid/\")\n",
    "        self.test_metrics = metrics.clone(prefix=\"test/\")\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        pts = batch[\"patients\"]\n",
    "        pts = [pt.to_gpu(non_block=True) for pt in pts]\n",
    "\n",
    "        concated_reprs = torch.zeros((len(pts), self.repr_dims[\"total\"]), device=self.device)\n",
    "\n",
    "        # ehr\n",
    "        concated_reprs[:, :self.ehr_model.repr_dim] = self.ehr_model(pts)\n",
    "            \n",
    "        # other modalities \n",
    "        if \"mri\" in batch.keys():\n",
    "            # mri_input.to(self.device)\n",
    "            concated_reprs[:, 3328:3358] = self.mri_model(batch[\"mri\"])\n",
    "        if \"dna\" in batch.keys():\n",
    "            # dna_input.to(self.device)\n",
    "            concated_reprs[:, 3358:3388] = self.dna_model(batch[\"dna\"])\n",
    "        if \"ecg\" in batch.keys():\n",
    "            # ecg_input.to(self.device)\n",
    "            concated_reprs[:, 3388:] = self.ecg_model(batch[\"ecg\"])\n",
    "\n",
    "        # send through fusion\n",
    "        # concated_reprs.to(self.device, non_blocking=True)\n",
    "        return self.model(concated_reprs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        yb = batch[\"ys\"]\n",
    "        y_hat = self(batch)\n",
    "        train_loss = self.train_loss_fn(y_hat, yb)\n",
    "\n",
    "        self.log(\"train_loss\", train_loss, on_step=True, on_epoch=True)\n",
    "        self.train_metrics.update(y_hat, yb.int())\n",
    "        self.log_dict(self.train_metrics.compute(), on_step=False, on_epoch=True)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        yb = batch[\"ys\"]\n",
    "        y_hat = self(batch)\n",
    "        valid_loss = self.valid_loss_fn(y_hat, yb)\n",
    "\n",
    "        self.log(\"valid_loss\", valid_loss, on_step=True, on_epoch=True)\n",
    "        self.valid_metrics.update(y_hat, yb.int())\n",
    "        self.log_dict(self.valid_metrics.compute(), on_step=False, on_epoch=True)\n",
    "\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        yb = batch[\"ys\"]\n",
    "        y_hat = self(batch)\n",
    "        \n",
    "        self.test_metrics.update(y_hat, yb.int())\n",
    "        self.log_dict(self.test_metrics.compute(), on_step=False, on_epoch=True)\n",
    "\n",
    "        return \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fusion_model = JointFusion(\n",
    "    demograph_dims,\n",
    "    rec_dims,\n",
    "    demograph_dims_wd,\n",
    "    rec_dims_wd,\n",
    "    len(COHERENT_LABELS),\n",
    "    pos_wts[\"train\"], \n",
    "    pos_wts[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "fusion_trainer = pl.Trainer(precision=16, accelerator='gpu', devices=-1, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:117: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | train_loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | valid_loss_fn | BCEWithLogitsLoss | 0     \n",
      "2 | ehr_model     | EHR_LSTM          | 7.6 M \n",
      "3 | mri_model     | UnimodalModel     | 850   \n",
      "4 | dna_model     | UnimodalModel     | 850   \n",
      "5 | ecg_model     | UnimodalModel     | 850   \n",
      "6 | model         | Sequential        | 33.7 M\n",
      "7 | train_metrics | MetricCollection  | 0     \n",
      "8 | valid_metrics | MetricCollection  | 0     \n",
      "9 | test_metrics  | MetricCollection  | 0     \n",
      "----------------------------------------------------\n",
      "41.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "41.4 M    Total params\n",
      "82.704    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1891: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [00:01<00:00,  4.28it/s, loss=0.993, v_num=23]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  2.72it/s, loss=0.993, v_num=23]\n"
     ]
    }
   ],
   "source": [
    "fusion_trainer.fit(fusion_model, train_dataloaders=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 16.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/AUROC         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.55997633934021      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/AUROC        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.55997633934021     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/AUROC': 0.55997633934021}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_trainer.test(fusion_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('lemonpie')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5f90d37e0c39959df55936ee810057807de324814919599137c4c82f94e911f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
