{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from lemonpie.basics import *\n",
    "from lemonpie.preprocessing import vocab\n",
    "from lemonpie.preprocessing.transform import *\n",
    "from lemonpie.data import *\n",
    "from lemonpie import models\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import MetricCollection, AUROC, Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERENT_DATA_STORE = '/home/vinod/code/datasets/coherent'\n",
    "COHERENT_DATAGEN_DATE = '08-10-2021'\n",
    "COHERENT_CONDITIONS = {\n",
    "    \"heart_failure\" : \"88805009\",\n",
    "    \"coronary_heart\" : \"53741008\",\n",
    "    \"myocardial_infarction\" : \"22298006\",\n",
    "    \"stroke\" : \"230690007\",\n",
    "    \"cardiac_arrest\" : \"410429000\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heart_failure',\n",
       " 'coronary_heart',\n",
       " 'myocardial_infarction',\n",
       " 'stroke',\n",
       " 'cardiac_arrest']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COHERENT_LABELS = list(COHERENT_CONDITIONS.keys())\n",
    "COHERENT_LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518ae1be-20ce-4e57-99b3-44dada24b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherent_data = MultimodalEHRData(\n",
    "    COHERENT_DATA_STORE, \n",
    "    COHERENT_LABELS,     \n",
    "    age_start=240,\n",
    "    age_range=120,\n",
    "    start_is_date=False,\n",
    "    age_in_months=True, \n",
    "    lazy_load_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demograph_dims, rec_dims, demograph_dims_wd, rec_dims_wd = vocab.get_all_emb_dims(vocab.EhrVocabList.load(COHERENT_DATA_STORE))\n",
    "dls, pos_wts = coherent_data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['0', '21', '30', '31', '11', '1', '20', '10'],\n",
       " 'valid': ['21', '30', '31', '11', '1', '20', '10'],\n",
       " 'test': ['21', '30', '31', '11', '1', '20', '10']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherent_data.modality_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fa4d8c79e20>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7fa4d87b6790>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7fa4d8756280>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dls[\"train\"]\n",
    "valid_dl = dls[\"valid\"]\n",
    "test_dl = dls[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimodal Models - One Per Modality\n",
    "These are stubs / dummys to be replaced by the real ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnimodalModel(pl.LightningModule):\n",
    "    def __init__(self, input_dims: tuple):\n",
    "        super().__init__()\n",
    "\n",
    "        # args\n",
    "        self.input_dims = input_dims\n",
    "\n",
    "        # model\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 5),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x[0].size() == self.input_dims, f\"Expected {self.input_dims}, got {x[0].size()}\"\n",
    "        bs = len(x)\n",
    "        fake_x = torch.randn((bs, 10), device=self.device)\n",
    "        return self.model(fake_x)\n",
    "\n",
    "    def training_step(self, *args, **kwargs):\n",
    "        return super().training_step(*args, **kwargs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return super().configure_optimizers()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4827, 0.4370, 0.5291, 0.4324, 0.5247],\n",
       "        [0.4691, 0.4958, 0.5113, 0.4747, 0.5402],\n",
       "        [0.4821, 0.4977, 0.5239, 0.4663, 0.5329]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_model = UnimodalModel((4,4))\n",
    "mri_model(torch.randn(3,4,4)) # batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "mri_trainer = pl.Trainer(max_epochs=3, accelerator='gpu', devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/core/module.py:1368: UserWarning: `configure_optimizers` must be implemented to be used with the Lightning Trainer\n",
      "  rank_zero_warn(\"`configure_optimizers` must be implemented to be used with the Lightning Trainer\")\n",
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py:182: UserWarning: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.0 K \n",
      "-------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/21 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1891: PossibleUserWarning: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   5%|▍         | 1/21 [00:01<00:26,  1.34s/it, loss=nan, v_num=34]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/core/module.py:670: UserWarning: `training_step` must be implemented to be used with the Lightning Trainer\n",
      "  rank_zero_warn(\"`training_step` must be implemented to be used with the Lightning Trainer\")\n",
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:135: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:03<00:00,  6.81it/s, loss=nan, v_num=34]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:03<00:00,  6.80it/s, loss=nan, v_num=34]\n"
     ]
    }
   ],
   "source": [
    "mri_trainer.fit(mri_model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_trainer.save_checkpoint(\"./mri_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real MRI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.io import read_image\n",
    "# from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "# import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class MRIDataset(Dataset):\n",
    "\n",
    "    def __init__(self, datastore: str) -> None:\n",
    "        self.data_dir = Path(f\"{datastore}/processed/mri\")\n",
    "        self.mri_png_paths = list(self.data_dir.glob('*.png'))  # list of mri slices as png images\n",
    "        self.img_size = 128\n",
    "\n",
    "    def find_mri_png_paths(self, patient_id: str) -> list:\n",
    "        \"\"\"\n",
    "        For each patient, find the corresponding paths to the MRI .png images\n",
    "        and return them in a list\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for path in self.mri_png_paths:\n",
    "            if patient_id in path.name:\n",
    "                res.append(path)\n",
    "        return res\n",
    "\n",
    "    def __getitem__(self, patient_id):\n",
    "        \"\"\"\n",
    "        Return all torch Tensors of MRI slices of a patient and his/her condition labels\n",
    "        \"\"\"\n",
    "        png_paths = self.find_mri_png_paths(patient_id)\n",
    "        data = []\n",
    "        for path in png_paths:\n",
    "            img = read_image(str(path))\n",
    "            img = img.type(torch.FloatTensor) \n",
    "            img = transforms.Resize((self.img_size, self.img_size))(img)\n",
    "            data.append(img)\n",
    "        data = torch.stack(data[:115])\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mri_png_paths)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_ds = MRIDataset(COHERENT_DATA_STORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptids = ['fec6d99f-1cfd-f397-e740-e3952410ea2a', 'fd83348f-f088-3a44-b8cc-faa955eca3a1', '6dc8bd6b-e2a8-92bf-613d-8b477eb87d7c']\n",
    "# for ptid in ptids:\n",
    "#     mri_input = mri_ds[ptid]\n",
    "#     print(mri_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.resnet = resnet18()\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7),  # change input channel to be 1 instead of 3 \n",
    "                                      stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        # add a linear layer at the end for transfer learning\n",
    "        self.linear = nn.Linear(in_features=self.resnet.fc.out_features,\n",
    "                                out_features=5)\n",
    "        self.save_hyperparameters()  # log hyperparameters\n",
    "\n",
    "    # optionally, define a forward method\n",
    "    def forward(self, xs):\n",
    "        pts = xs.shape[0]\n",
    "        all_y_hats = []\n",
    "        for pt in range(pts):\n",
    "            y_hats = self.resnet(xs[pt])\n",
    "            y_hats = self.linear(y_hats)\n",
    "            y_hats = torch.mean(y_hats, dim=0)\n",
    "            all_y_hats.append(y_hats)\n",
    "\n",
    "        res = torch.stack(all_y_hats)\n",
    "        return res  # we like to just call the model's forward method\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if \"mri\" in batch.keys():\n",
    "            xs, ys = batch[\"mri\"], batch[\"ys\"]\n",
    "            y_hats = self.forward(xs)\n",
    "            loss = F.binary_cross_entropy_with_logits(y_hats, ys)\n",
    "            self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True, on_step=True)\n",
    "            return loss\n",
    "        else:\n",
    "            return \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if \"mri\" in batch.keys():\n",
    "            xs, ys = batch[\"mri\"], batch[\"ys\"]\n",
    "            y_hats = self.forward(xs)\n",
    "            loss = F.binary_cross_entropy_with_logits(y_hats, ys)\n",
    "            self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True, on_step=True)\n",
    "            return loss\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "    # def test_step(self, xs, batch_idx):\n",
    "    #     y_hats = self.resnet(xs)\n",
    "    #     y_hats = self.linear(y_hats)\n",
    "    #     return y_hats\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri_model = MRIModel.load_from_checkpoint(\"./mri_model_ckpt.pth\")\n",
    "# mri_model = torch.load(\"./mri_model_ckpt.pth\")\n",
    "mri_model = MRIModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hats = mri_model(batch[\"mri\"])\n",
    "# mean_y_hats = torch.mean(y_hats, dim=0)\n",
    "# torch.sigmoid(mean_y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0478, -0.0757, -0.1002,  0.1936, -0.2731],\n",
       "        [ 0.0477, -0.0718, -0.0998,  0.1903, -0.2689],\n",
       "        [ 0.0489, -0.0728, -0.0984,  0.1927, -0.2670]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "mri_trainer = pl.Trainer(accelerator='gpu', devices=-1, max_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri_trainer.fit(mri_model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_layers_trunc = list(mri_model.children())[:-1]\n",
    "trunc_mri_model = nn.Sequential(*mri_layers_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri_reprs = trunc_mri_model(mri_input)\n",
    "# mean_mri_reprs = torch.mean(mri_reprs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_mri_reprs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5450, 0.5458, 0.5251, 0.5495],\n",
       "        [0.4860, 0.5420, 0.5555, 0.5264, 0.5618]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_model = UnimodalModel((3,2))\n",
    "dna_model(torch.randn(2,3,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "dna_trainer = pl.Trainer(max_epochs=3, accelerator='gpu', devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.0 K \n",
      "-------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:02<00:00,  7.26it/s, loss=nan, v_num=31]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:02<00:00,  7.25it/s, loss=nan, v_num=31]\n"
     ]
    }
   ],
   "source": [
    "dna_trainer.fit(dna_model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_trainer.save_checkpoint(\"./dna_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5045, 0.5088, 0.4852, 0.5392, 0.4659],\n",
       "        [0.5082, 0.5088, 0.4802, 0.5626, 0.4721],\n",
       "        [0.5293, 0.5082, 0.4893, 0.5951, 0.5158],\n",
       "        [0.5302, 0.5078, 0.4481, 0.4545, 0.4459]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_model = UnimodalModel((5,))\n",
    "ecg_model(torch.randn((4,5,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "ecg_trainer = pl.Trainer(max_epochs=3, accelerator='gpu', devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.0 K \n",
      "-------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:02<00:00,  7.19it/s, loss=nan, v_num=32]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 21/21 [00:02<00:00,  7.18it/s, loss=nan, v_num=32]\n"
     ]
    }
   ],
   "source": [
    "ecg_trainer.fit(ecg_model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_trainer.save_checkpoint(\"./ecg_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ehr_model = models.EHR_LSTM(\n",
    "    demograph_dims,\n",
    "    rec_dims,\n",
    "    demograph_dims_wd,\n",
    "    rec_dims_wd,\n",
    "    len(COHERENT_LABELS),\n",
    "    pos_wts[\"train\"], \n",
    "    pos_wts[\"valid\"],\n",
    "    optim=\"adam\",\n",
    "    base_lr=0.001,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "ehr_trainer = pl.Trainer(precision=16, accelerator='gpu', devices=-1, max_epochs=3)\n",
    "# ehr_output = ehr_trainer.test(ehr_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | train_loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | valid_loss_fn | BCEWithLogitsLoss | 0     \n",
      "2 | embs          | ModuleList        | 12.0 K\n",
      "3 | embgs         | ModuleList        | 19.5 K\n",
      "4 | input_dp      | InputDropout      | 0     \n",
      "5 | lstm          | LSTM              | 250 K \n",
      "6 | linear        | Sequential        | 7.4 M \n",
      "7 | train_metrics | MetricCollection  | 0     \n",
      "8 | valid_metrics | MetricCollection  | 0     \n",
      "9 | test_metrics  | MetricCollection  | 0     \n",
      "----------------------------------------------------\n",
      "7.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 M     Total params\n",
      "15.320    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/28 [00:00<?, ?it/s]                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1891: PossibleUserWarning: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 28/28 [00:08<00:00,  3.32it/s, loss=1.02, v_num=35]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 28/28 [00:08<00:00,  3.25it/s, loss=1.02, v_num=35]\n"
     ]
    }
   ],
   "source": [
    "ehr_trainer.fit(ehr_model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Lightning warning details](https://github.com/Lightning-AI/lightning/issues/10349#issuecomment-961340903)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_trainer.save_checkpoint(\"./ehr_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimodal Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class MRIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datastore: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        self.mri_dir = f\"{datastore}/output/dicom\"\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        mri_fname = glob.glob(f\"{self.mri_dir}/*{i}*\")\n",
    "        if len(mri_fname) == 1:\n",
    "            return torch.full(self.tensor_sz, 1)\n",
    "        else:\n",
    "            raise Exception(f\"MRI filename match error - found {len(mri_fname)} files with ptid: {i}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class DNADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datastore: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        self.dna_dir = f\"{datastore}/output/dna\"\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        dna_fname = glob.glob(f\"{self.dna_dir}/*{i}*\")\n",
    "        if len(dna_fname) == 1:\n",
    "            return torch.full(self.tensor_sz, 10)\n",
    "        else:\n",
    "            raise Exception(f\"DNA filename match error - found {len(dna_fname)} files with ptid: {i}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class ECGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datastore: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        ecg_data = pd.read_csv(f\"{datastore}/ecg.csv\")\n",
    "        self.ecg_pids = ecg_data.patient.unique()\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        if i in self.ecg_pids:\n",
    "            return torch.full(self.tensor_sz, 20)\n",
    "        else:\n",
    "            raise Exception(f\"ptid: {i} - not found in ECG data.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modality Type | Modalities            |   \n",
    "|---\t        |---\t                |\n",
    "| **0**\t        | **EHR**               |\n",
    "| **1**         | EHR + **MRI**         |\n",
    "| **10**        | EHR + **DNA**         |      \n",
    "| 11   \t        | EHR + MRI + DNA       |\n",
    "| **20**        | EHR + **ECG**         |\n",
    "| 21            | EHR + MRI + ECG       |\n",
    "| 30            | EHR + DNA + ECG       |\n",
    "| 31            | EHR + MRI + DNA + ECG |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patients': [ptid:1a82483d-7eb2-d5e0-1e1f-398ba129b18b, birthdate:1936-12-22, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       "  ptid:6dc8bd6b-e2a8-92bf-613d-8b477eb87d7c, birthdate:1911-12-23, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       "  ptid:844a37ff-ce26-6338-fd6a-0bc1e925a702, birthdate:1933-03-15, [('heart_failure', True), ('coronary_heart', False)].., device:cpu],\n",
       " 'ys': tensor([[1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.]]),\n",
       " 'mri': tensor([[[1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1]],\n",
       " \n",
       "         [[1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1]],\n",
       " \n",
       "         [[1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1]]]),\n",
       " 'ecg': tensor([[20, 20, 20, 20, 20],\n",
       "         [20, 20, 20, 20, 20],\n",
       "         [20, 20, 20, 20, 20]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(valid_dl))   \n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5964, 0.5248, 0.4754, 0.4943, 0.6138],\n",
       "        [0.5518, 0.5288, 0.5270, 0.5399, 0.5448],\n",
       "        [0.5626, 0.4570, 0.4899, 0.4378, 0.6217]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(ehr_model(batch[\"patients\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_input, ecg_input = batch[\"mri\"], batch[\"ecg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4853, 0.4834, 0.5167, 0.4784, 0.5325],\n",
       "        [0.5083, 0.5090, 0.5161, 0.4914, 0.5421],\n",
       "        [0.5048, 0.4745, 0.5100, 0.4634, 0.5208]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_model(mri_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5326, 0.5161, 0.4775, 0.5335, 0.4699],\n",
       "        [0.5141, 0.5114, 0.4913, 0.5569, 0.4736],\n",
       "        [0.5312, 0.4955, 0.4771, 0.5711, 0.4843]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_model(ecg_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_late_fusion(dl, verbose=False):\n",
    "\n",
    "    all_batches = []\n",
    "    total_length = 0\n",
    "\n",
    "    for batch in dl:\n",
    "\n",
    "        batch_output = []\n",
    "        pts = batch[\"patients\"]\n",
    "        \n",
    "        total_length += len(pts)\n",
    "        if verbose:\n",
    "            print(f\"batch size: {len(pts)}, first ptid: {pts[0].ptid}\")\n",
    "\n",
    "        batch_output.append(torch.sigmoid(ehr_model(pts)))\n",
    "\n",
    "        # other modalities \n",
    "        if \"mri\" in batch.keys():\n",
    "            batch_output.append(mri_model(batch[\"mri\"]))\n",
    "        if \"dna\" in batch.keys():\n",
    "            batch_output.append(dna_model(batch[\"dna\"]))\n",
    "        if \"ecg\" in batch.keys():\n",
    "            batch_output.append(ecg_model(batch[\"ecg\"]))\n",
    "\n",
    "        # avg across multimodal models for every patient in batch\n",
    "        avgd = torch.mean(torch.stack(batch_output), dim=0)         \n",
    "        all_batches.append(avgd)\n",
    "\n",
    "\n",
    "    print(f\"Completed {total_length} patients.\")\n",
    "\n",
    "    # flatten across batches - list of lists (batches) to flat\n",
    "    output = [pt for batch in all_batches for pt in batch]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 128 patients.\n"
     ]
    }
   ],
   "source": [
    "test_result = run_late_fusion(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 3, first ptid: 1a82483d-7eb2-d5e0-1e1f-398ba129b18b\n",
      "batch size: 13, first ptid: 2e1cf98c-70ce-4f8f-36da-b2eef4960ecc\n",
      "batch size: 2, first ptid: 4a1a224f-54d6-66f1-3755-4c8489f2a5de\n",
      "batch size: 14, first ptid: aead835e-66f2-d3b9-099c-c33844a70748\n",
      "batch size: 12, first ptid: 972f6a59-3921-36bc-64bb-253d6241748b\n",
      "batch size: 34, first ptid: e1875ec6-e10f-c9d8-d388-fd3abfbc4a87\n",
      "batch size: 50, first ptid: 1e73e6da-68f0-0ffc-4062-a4647b5b67c4\n",
      "Completed 128 patients.\n"
     ]
    }
   ],
   "source": [
    "valid_result = run_late_fusion(valid_dl, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1022 patients.\n"
     ]
    }
   ],
   "source": [
    "train_result = run_late_fusion(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_result) == len(valid_result) == 128\n",
    "assert len(train_result) == 1022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts, y, m, other = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patients'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_model = UnimodalModel.load_from_checkpoint(\"./mri_model_pth\", input_dims=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_layers_trunc = list(mri_model.model.children())[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_model.model = nn.Sequential(*mri_layers_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mri_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_repr = mri_model(mri_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 30])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_repr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ehr_model = models.EHR_LSTM.load_from_checkpoint(\n",
    "    \"./ehr_model_pth\",\n",
    "    demograph_dims=demograph_dims,\n",
    "    rec_dims=rec_dims,\n",
    "    demograph_dims_wd=demograph_dims_wd,\n",
    "    rec_dims_wd=rec_dims_wd,\n",
    "    labels=len(COHERENT_LABELS),\n",
    "    train_pos_wts=pos_wts[\"train\"], \n",
    "    valid_pos_wts=pos_wts[\"valid\"],\n",
    "    optim=\"adam\",\n",
    "    base_lr=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_layers_trunc = list(ehr_model.linear.children())[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_model.linear = nn.Sequential(*ehr_layers_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ehr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ehr_repr = ehr_model(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3328])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ehr_repr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated = torch.concat((ehr_repr, mri_repr), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3358])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointFusion(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "            demograph_dims,\n",
    "            rec_dims,\n",
    "            demograph_wd,\n",
    "            rec_wd,\n",
    "            num_labels,\n",
    "            train_pos_wts,\n",
    "            valid_pos_wts\n",
    "            ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        ## args\n",
    "        self.train_loss_fn = nn.BCEWithLogitsLoss(pos_weight=train_pos_wts)\n",
    "        self.valid_loss_fn = nn.BCEWithLogitsLoss(pos_weight=valid_pos_wts)\n",
    "\n",
    "\n",
    "        # ehr\n",
    "        self.ehr_model = models.EHR_LSTM.load_from_checkpoint(\n",
    "            \"./ehr_model.pth\",\n",
    "            demograph_dims=demograph_dims,\n",
    "            rec_dims=rec_dims,\n",
    "            demograph_dims_wd=demograph_dims_wd,\n",
    "            rec_dims_wd=rec_dims_wd,\n",
    "            labels=len(COHERENT_LABELS),\n",
    "            train_pos_wts=pos_wts[\"train\"], \n",
    "            valid_pos_wts=pos_wts[\"valid\"],\n",
    "            optim=\"adam\",\n",
    "            base_lr=0.001,\n",
    "        )\n",
    "        ehr_layers_trunc = list(self.ehr_model.linear.children())[:-2]\n",
    "        self.ehr_model.linear = nn.Sequential(*ehr_layers_trunc)\n",
    "\n",
    "        # mri\n",
    "        self.mri_model = UnimodalModel.load_from_checkpoint(\"./mri_model.pth\", input_dims=(4,4))\n",
    "        mri_layers_trunc = list(self.mri_model.model.children())[:-2]\n",
    "        self.mri_model.model = nn.Sequential(*mri_layers_trunc)\n",
    "        \n",
    "        # dna\n",
    "        self.dna_model = UnimodalModel.load_from_checkpoint(\"./dna_model.pth\", input_dims=(3,2))\n",
    "        dna_layers_trunc = list(self.dna_model.model.children())[:-2]\n",
    "        self.dna_model.model = nn.Sequential(*dna_layers_trunc)\n",
    "\n",
    "        # ecg\n",
    "        self.ecg_model = UnimodalModel.load_from_checkpoint(\"./ecg_model.pth\", input_dims=(5,))\n",
    "        ecg_layers_trunc = list(self.ecg_model.model.children())[:-2]\n",
    "        self.ecg_model.model = nn.Sequential(*ecg_layers_trunc)\n",
    "\n",
    "        # model\n",
    "        self.repr_dims = {}\n",
    "        self.repr_dims[\"ehr\"] = self.ehr_model.repr_dim\n",
    "        self.repr_dims[\"mri\"] = 30\n",
    "        self.repr_dims[\"dna\"] = 30\n",
    "        self.repr_dims[\"ecg\"] = 30\n",
    "        self.repr_dims[\"total\"] = sum(self.repr_dims.values())\n",
    "\n",
    "        self.model = nn.Sequential(nn.Linear(self.repr_dims[\"total\"], 4000),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(4000, 5000),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(5000, 5),\n",
    "                      nn.Sigmoid())\n",
    "        \n",
    "        ## metrics\n",
    "        metrics = MetricCollection(\n",
    "            [\n",
    "                # Accuracy(),\n",
    "                AUROC(num_classes=num_labels, pos_label=1, average=\"micro\"),\n",
    "                # Recall(),\n",
    "                # Precision(),\n",
    "                # AveragePrecision(num_classes)\n",
    "            ]\n",
    "        )\n",
    "        self.train_metrics = metrics.clone(prefix=\"train/\")\n",
    "        self.valid_metrics = metrics.clone(prefix=\"valid/\")\n",
    "        self.test_metrics = metrics.clone(prefix=\"test/\")\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        pts = batch[\"patients\"]\n",
    "        pts = [pt.to_gpu(non_block=True) for pt in pts]\n",
    "\n",
    "        concated_reprs = torch.zeros((len(pts), self.repr_dims[\"total\"]), device=self.device)\n",
    "\n",
    "        # ehr\n",
    "        concated_reprs[:, :self.ehr_model.repr_dim] = self.ehr_model(pts)\n",
    "            \n",
    "        # other modalities \n",
    "        if \"mri\" in batch.keys():\n",
    "            # mri_input.to(self.device)\n",
    "            concated_reprs[:, 3328:3358] = self.mri_model(batch[\"mri\"])\n",
    "        if \"dna\" in batch.keys():\n",
    "            # dna_input.to(self.device)\n",
    "            concated_reprs[:, 3358:3388] = self.dna_model(batch[\"dna\"])\n",
    "        if \"ecg\" in batch.keys():\n",
    "            # ecg_input.to(self.device)\n",
    "            concated_reprs[:, 3388:] = self.ecg_model(batch[\"ecg\"])\n",
    "\n",
    "        # send through fusion\n",
    "        # concated_reprs.to(self.device, non_blocking=True)\n",
    "        return self.model(concated_reprs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        yb = batch[\"ys\"]\n",
    "        y_hat = self(batch)\n",
    "        train_loss = self.train_loss_fn(y_hat, yb)\n",
    "\n",
    "        self.log(\"train_loss\", train_loss, on_step=True, on_epoch=True)\n",
    "        self.train_metrics.update(y_hat, yb.int())\n",
    "        self.log_dict(self.train_metrics.compute(), on_step=False, on_epoch=True)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        yb = batch[\"ys\"]\n",
    "        y_hat = self(batch)\n",
    "        valid_loss = self.valid_loss_fn(y_hat, yb)\n",
    "\n",
    "        self.log(\"valid_loss\", valid_loss, on_step=True, on_epoch=True)\n",
    "        self.valid_metrics.update(y_hat, yb.int())\n",
    "        self.log_dict(self.valid_metrics.compute(), on_step=False, on_epoch=True)\n",
    "\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        yb = batch[\"ys\"]\n",
    "        y_hat = self(batch)\n",
    "        \n",
    "        self.test_metrics.update(y_hat, yb.int())\n",
    "        self.log_dict(self.test_metrics.compute(), on_step=False, on_epoch=True)\n",
    "\n",
    "        return \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fusion_model = JointFusion(\n",
    "    demograph_dims,\n",
    "    rec_dims,\n",
    "    demograph_dims_wd,\n",
    "    rec_dims_wd,\n",
    "    len(COHERENT_LABELS),\n",
    "    pos_wts[\"train\"], \n",
    "    pos_wts[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "fusion_trainer = pl.Trainer(precision=16, accelerator='gpu', devices=-1, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:117: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | train_loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | valid_loss_fn | BCEWithLogitsLoss | 0     \n",
      "2 | ehr_model     | EHR_LSTM          | 7.6 M \n",
      "3 | mri_model     | UnimodalModel     | 850   \n",
      "4 | dna_model     | UnimodalModel     | 850   \n",
      "5 | ecg_model     | UnimodalModel     | 850   \n",
      "6 | model         | Sequential        | 33.7 M\n",
      "7 | train_metrics | MetricCollection  | 0     \n",
      "8 | valid_metrics | MetricCollection  | 0     \n",
      "9 | test_metrics  | MetricCollection  | 0     \n",
      "----------------------------------------------------\n",
      "41.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "41.4 M    Total params\n",
      "82.704    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinod/anaconda3/envs/lemonpie/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1891: PossibleUserWarning: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  3.18it/s, loss=1.01, v_num=36] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 7/7 [00:03<00:00,  2.24it/s, loss=1.01, v_num=36]\n"
     ]
    }
   ],
   "source": [
    "fusion_trainer.fit(fusion_model, train_dataloaders=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 16.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/AUROC         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5192548036575317     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/AUROC        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5192548036575317    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/AUROC': 0.5192548036575317}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_trainer.test(fusion_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('lemonpie')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5f90d37e0c39959df55936ee810057807de324814919599137c4c82f94e911f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
